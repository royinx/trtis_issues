{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ed7798c",
   "metadata": {},
   "source": [
    "\n",
    "docker run --name=deploy_trt1912 --rm -it --runtime nvidia -v ${PWD}:/py -w /py -p 20082:8888 nvcr.io/nvidia/tensorrt:19.12-py3 bash\n",
    "\n",
    "pip3 install notebook\n",
    "\n",
    "jupyter notebook --allow-root --ip 0.0.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13be41ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import tensorrt as trt\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de6b66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6.0.1.8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79e6eab3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in /usr/local/lib/python3.6/dist-packages (1.9.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from onnx) (3.17.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from onnx) (1.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx) (3.10.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.6/dist-packages (from onnx) (1.17.4)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f3e91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_test4axis1.onnx\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnx.helper as oh\n",
    "from onnx import checker\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import sys\n",
    "import os\n",
    "\n",
    "AXIS = 1\n",
    "SHAPE = [1, 3, 4, 5]\n",
    "# SHAPE = [1, 1, 3, 4, 5]\n",
    "ONNX_FILE = f\"softmax_test{len(SHAPE)}axis{AXIS}.onnx\"\n",
    "\n",
    "# Generate ONNX model\n",
    "def generate_model(io_shape=SHAPE, axis=AXIS):\n",
    "    in_tensor = [\n",
    "        oh.make_tensor_value_info(\"Input\", onnx.TensorProto.FLOAT, io_shape)\n",
    "    ]\n",
    "    out_tensor = [\n",
    "        oh.make_tensor_value_info(\"Output\", onnx.TensorProto.FLOAT, io_shape)\n",
    "    ]\n",
    "    nodes = []\n",
    "    nodes.append(oh.make_node(\"Softmax\", axis=axis, \\\n",
    "        inputs=[\"Input\"], outputs=[\"Output\"]))\n",
    "    graph = oh.make_graph(nodes, \"Test Graph\", in_tensor, out_tensor)\n",
    "    checker.check_graph(graph)\n",
    "    model = oh.make_model(graph, producer_name=\"MACNICA\", \\\n",
    "        producer_version=\"0.1\")\n",
    "    checker.check_model(model)\n",
    "    with open(ONNX_FILE, \"wb\") as f:\n",
    "        f.write(model.SerializeToString())\n",
    "\n",
    "generate_model(SHAPE, AXIS)\n",
    "print(ONNX_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42631996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec # trtexec --onnx=softmax_test4axis1.onnx --saveEngine=softmax_test4axis1_trt6.trt --explicitBatch --fp16 --verbose --dumpOutput\n",
      "[04/24/2021-13:32:55] [I] === Model Options ===\n",
      "[04/24/2021-13:32:55] [I] Format: ONNX\n",
      "[04/24/2021-13:32:55] [I] Model: softmax_test4axis1.onnx\n",
      "[04/24/2021-13:32:55] [I] Output:\n",
      "[04/24/2021-13:32:55] [I] === Build Options ===\n",
      "[04/24/2021-13:32:55] [I] Max batch: explicit\n",
      "[04/24/2021-13:32:55] [I] Workspace: 16 MB\n",
      "[04/24/2021-13:32:55] [I] minTiming: 1\n",
      "[04/24/2021-13:32:55] [I] avgTiming: 8\n",
      "[04/24/2021-13:32:55] [I] Precision: FP16\n",
      "[04/24/2021-13:32:55] [I] Calibration: \n",
      "[04/24/2021-13:32:55] [I] Safe mode: Disabled\n",
      "[04/24/2021-13:32:55] [I] Save engine: softmax_test4axis1_trt6.trt\n",
      "[04/24/2021-13:32:55] [I] Load engine: \n",
      "[04/24/2021-13:32:55] [I] Inputs format: fp32:CHW\n",
      "[04/24/2021-13:32:55] [I] Outputs format: fp32:CHW\n",
      "[04/24/2021-13:32:55] [I] Input build shapes: model\n",
      "[04/24/2021-13:32:55] [I] === System Options ===\n",
      "[04/24/2021-13:32:55] [I] Device: 0\n",
      "[04/24/2021-13:32:55] [I] DLACore: \n",
      "[04/24/2021-13:32:55] [I] Plugins:\n",
      "[04/24/2021-13:32:55] [I] === Inference Options ===\n",
      "[04/24/2021-13:32:55] [I] Batch: Explicit\n",
      "[04/24/2021-13:32:55] [I] Iterations: 10 (200 ms warm up)\n",
      "[04/24/2021-13:32:55] [I] Duration: 10s\n",
      "[04/24/2021-13:32:55] [I] Sleep time: 0ms\n",
      "[04/24/2021-13:32:55] [I] Streams: 1\n",
      "[04/24/2021-13:32:55] [I] Spin-wait: Disabled\n",
      "[04/24/2021-13:32:55] [I] Multithreading: Enabled\n",
      "[04/24/2021-13:32:55] [I] CUDA Graph: Disabled\n",
      "[04/24/2021-13:32:55] [I] Skip inference: Disabled\n",
      "[04/24/2021-13:32:55] [I] === Reporting Options ===\n",
      "[04/24/2021-13:32:55] [I] Verbose: Enabled\n",
      "[04/24/2021-13:32:55] [I] Averages: 10 inferences\n",
      "[04/24/2021-13:32:55] [I] Percentile: 99\n",
      "[04/24/2021-13:32:55] [I] Dump output: Enabled\n",
      "[04/24/2021-13:32:55] [I] Profile: Disabled\n",
      "[04/24/2021-13:32:55] [I] Export timing to JSON file: \n",
      "[04/24/2021-13:32:55] [I] Export profile to JSON file: \n",
      "[04/24/2021-13:32:55] [I] \n",
      "[04/24/2021-13:32:55] [V] [TRT] Plugin Creator registration succeeded - GridAnchor_TRT\n",
      "[04/24/2021-13:32:55] [V] [TRT] Plugin Creator registration succeeded - NMS_TRT\n",
      "[04/24/2021-13:32:55] [V] [TRT] Plugin Creator registration succeeded - Reorg_TRT\n",
      "[04/24/2021-13:32:55] [V] [TRT] Plugin Creator registration succeeded - Region_TRT\n",
      "[04/24/2021-13:32:55] [V] [TRT] Plugin Creator registration succeeded - Clip_TRT\n",
      "[04/24/2021-13:32:55] [V] [TRT] Plugin Creator registration succeeded - LReLU_TRT\n",
      "[04/24/2021-13:32:55] [V] [TRT] Plugin Creator registration succeeded - PriorBox_TRT\n",
      "[04/24/2021-13:32:55] [V] [TRT] Plugin Creator registration succeeded - Normalize_TRT\n",
      "[04/24/2021-13:32:55] [V] [TRT] Plugin Creator registration succeeded - RPROI_TRT\n",
      "[04/24/2021-13:32:55] [V] [TRT] Plugin Creator registration succeeded - BatchedNMS_TRT\n",
      "[04/24/2021-13:32:55] [V] [TRT] Plugin Creator registration succeeded - FlattenConcat_TRT\n",
      "----------------------------------------------------------------\n",
      "Input filename:   softmax_test4axis1.onnx\n",
      "ONNX IR version:  0.0.7\n",
      "Opset version:    14\n",
      "Producer name:    MACNICA\n",
      "Producer version: 0.1\n",
      "Domain:           \n",
      "Model version:    0\n",
      "Doc string:       \n",
      "----------------------------------------------------------------\n",
      "WARNING: ONNX model has a newer ir_version (0.0.7) than this parser was built against (0.0.3).\n",
      "[04/24/2021-13:32:55] [V] [TRT] Output:Softmax -> (3, 4, 5)\n",
      " ----- Parsing of ONNX model softmax_test4axis1.onnx is Done ---- \n",
      "[04/24/2021-13:32:55] [V] [TRT] Applying generic optimizations to the graph for inference.\n",
      "[04/24/2021-13:32:55] [V] [TRT] Original: 1 layers\n",
      "[04/24/2021-13:32:55] [V] [TRT] After dead-layer removal: 1 layers\n",
      "[04/24/2021-13:32:55] [V] [TRT] After scale fusion: 1 layers\n",
      "[04/24/2021-13:32:55] [V] [TRT] After vertical fusions: 1 layers\n",
      "[04/24/2021-13:32:55] [V] [TRT] After final dead-layer removal: 1 layers\n",
      "[04/24/2021-13:32:55] [V] [TRT] After tensor merging: 1 layers\n",
      "[04/24/2021-13:32:55] [V] [TRT] After concat removal: 1 layers\n",
      "[04/24/2021-13:32:55] [V] [TRT] Graph construction and optimization completed in 0.000123452 seconds.\n",
      "[04/24/2021-13:32:56] [V] [TRT] Constructing optimization profile number 0 out of 1\n",
      "--------------- Timing Runner: <reformat> (Reformat)\n",
      "[04/24/2021-13:32:56] [V] [TRT] Tactic: 1002 time 0.004896\n",
      "[04/24/2021-13:32:56] [V] [TRT] Tactic: 0 time 0.005664\n",
      "[04/24/2021-13:32:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.004896\n",
      "[04/24/2021-13:32:56] [V] [TRT] *************** Autotuning format combination: Float(1,5,20) -> Float(1,5,20) ***************\n",
      "[04/24/2021-13:32:56] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 0) [Softmax] (SoftMax)\n",
      "[04/24/2021-13:32:56] [V] [TRT] Tactic: 1001 time 0.006144\n",
      "[04/24/2021-13:32:56] [V] [TRT] Fastest Tactic: 1001 Time: 0.006144\n",
      "[04/24/2021-13:32:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: SoftMax Tactic: 1001\n",
      "[04/24/2021-13:32:56] [V] [TRT] \n",
      "[04/24/2021-13:32:56] [V] [TRT] *************** Autotuning format combination: Half(1,5,20) -> Half(1,5,20) ***************\n",
      "[04/24/2021-13:32:56] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 0) [Softmax] (SoftMax)\n",
      "[04/24/2021-13:32:56] [V] [TRT] Tactic: 1001 time 0.006144\n",
      "[04/24/2021-13:32:56] [V] [TRT] Fastest Tactic: 1001 Time: 0.006144\n",
      "[04/24/2021-13:32:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: SoftMax Tactic: 1001\n",
      "[04/24/2021-13:32:56] [V] [TRT] \n",
      "[04/24/2021-13:32:56] [V] [TRT] --------------- Timing Runner: <reformat> (Reformat)\n",
      "[04/24/2021-13:32:56] [V] [TRT] Tactic: 1002 time 0.004896\n",
      "[04/24/2021-13:32:56] [V] [TRT] Tactic: 0 time 0.0048\n",
      "[04/24/2021-13:32:56] [V] [TRT] Fastest Tactic: 0 Time: 0.0048\n",
      "[04/24/2021-13:32:56] [V] [TRT] For layer (Unnamed Layer* 0) [Softmax] a non-conforming implementation was chosen than was requested i.e. requested layer computation precision and output precision types were ignored because it resulted in faster network performance. Enable strict mode to try force choose a conforming implementation.\n",
      "[04/24/2021-13:32:56] [V] [TRT] Formats and tactics selection completed in 0.0112579 seconds.\n",
      "[04/24/2021-13:32:56] [V] [TRT] After reformat layers: 1 layers\n",
      "[04/24/2021-13:32:56] [V] [TRT] Block size 16777216\n",
      "[04/24/2021-13:32:56] [V] [TRT] Total Activation Memory: 16777216\n",
      "[04/24/2021-13:32:56] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n",
      "[04/24/2021-13:32:56] [V] [TRT] Engine generation completed in 0.749287 seconds.\n",
      "[04/24/2021-13:32:56] [V] [TRT] Engine Layer Information:\n",
      "[04/24/2021-13:32:56] [V] [TRT] Layer: (Unnamed Layer* 0) [Softmax] (SoftMax), Tactic: 1001, Input[Float(4,5)] -> Output[Float(4,5)]\n",
      "[04/24/2021-13:32:56] [I] Average over 10 runs is 0.0094912 ms (host walltime is 0.029358 ms, 99% percentile time is 0.02048).\n",
      "[04/24/2021-13:32:56] [I] Average over 10 runs is 0.0080704 ms (host walltime is 0.0249389 ms, 99% percentile time is 0.008288).\n",
      "[04/24/2021-13:32:56] [I] Average over 10 runs is 0.0079328 ms (host walltime is 0.0240953 ms, 99% percentile time is 0.008192).\n",
      "[04/24/2021-13:32:56] [I] Average over 10 runs is 0.0076 ms (host walltime is 0.0236362 ms, 99% percentile time is 0.008384).\n",
      "[04/24/2021-13:32:56] [I] Average over 10 runs is 0.0071264 ms (host walltime is 0.0217409 ms, 99% percentile time is 0.008192).\n",
      "[04/24/2021-13:32:56] [I] Average over 10 runs is 0.0067648 ms (host walltime is 0.0212417 ms, 99% percentile time is 0.007488).\n",
      "[04/24/2021-13:32:56] [I] Average over 10 runs is 0.0066624 ms (host walltime is 0.0210316 ms, 99% percentile time is 0.007424).\n",
      "[04/24/2021-13:32:56] [I] Average over 10 runs is 0.0063872 ms (host walltime is 0.0216999 ms, 99% percentile time is 0.007328).\n",
      "[04/24/2021-13:32:56] [I] Average over 10 runs is 0.0064864 ms (host walltime is 0.0210987 ms, 99% percentile time is 0.007936).\n",
      "[04/24/2021-13:32:56] [I] Average over 10 runs is 0.0063616 ms (host walltime is 0.0210326 ms, 99% percentile time is 0.006816).\n",
      "[04/24/2021-13:32:56] [I] Dumping output tensor Output:\n",
      "[04/24/2021-13:32:56] [I] [0, 3, 4, 5]\n",
      "[04/24/2021-13:32:56] [I] 0.333333 0.333333 0.333333 0.333333 0.333333\n",
      "[04/24/2021-13:32:56] [I] 0.333333 0.333333 0.333333 0.333333 0.333333\n",
      "[04/24/2021-13:32:56] [I] 0.333333 0.333333 0.333333 0.333333 0.333333\n",
      "[04/24/2021-13:32:56] [I] 0.333333 0.333333 0.333333 0.333333 0.333333\n",
      "[04/24/2021-13:32:56] [I] 0.333333 0.333333 0.333333 0.333333 0.333333\n",
      "[04/24/2021-13:32:56] [I] 0.333333 0.333333 0.333333 0.333333 0.333333\n",
      "[04/24/2021-13:32:56] [I] 0.333333 0.333333 0.333333 0.333333 0.333333\n",
      "[04/24/2021-13:32:56] [I] 0.333333 0.333333 0.333333 0.333333 0.333333\n",
      "[04/24/2021-13:32:56] [I] 0.333333 0.333333 0.333333 0.333333 0.333333\n",
      "[04/24/2021-13:32:56] [I] 0.333333 0.333333 0.333333 0.333333 0.333333\n",
      "[04/24/2021-13:32:56] [I] 0.333333 0.333333 0.333333 0.333333 0.333333\n",
      "[04/24/2021-13:32:56] [I] 0.333333 0.333333 0.333333 0.333333 0.333333\n",
      "&&&& PASSED TensorRT.trtexec # trtexec --onnx=softmax_test4axis1.onnx --saveEngine=softmax_test4axis1_trt6.trt --explicitBatch --fp16 --verbose --dumpOutput\n"
     ]
    }
   ],
   "source": [
    "!trtexec --onnx=softmax_test4axis1.onnx --saveEngine=softmax_test4axis1_trt6.trt --explicitBatch --fp16 --verbose --dumpOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ce8a9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger(trt.Logger.VERBOSE)\n",
    "def load_engine(engine_file_path):\n",
    "    assert os.path.exists(engine_file_path)\n",
    "    print(f\"Reading engine from file {engine_file_path}\")\n",
    "    with open(engine_file_path,\"rb\") as f , trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        return runtime.deserialize_cuda_engine(f.read())\n",
    "\n",
    "def infer(engine):\n",
    "    input_image = np.ones((1,3,4,5))\n",
    "    with engine.create_execution_context() as context:\n",
    "        context.set_binding_shape(engine.get_binding_index(\"input\"),(1,3,4,5))\n",
    "        bindings = []\n",
    "        for binding in engine:\n",
    "            binding_idx = engine.get_binding_index(binding)\n",
    "            size = trt.volume(context.get_binding_shape(binding_idx))\n",
    "            dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
    "            if engine.binding_is_input(binding):\n",
    "                input_buffer = np.ascontiguousarray(input_image)\n",
    "                input_memory = cuda.mem_alloc(input_image.nbytes)\n",
    "                print(\"in\",list(engine.get_binding_shape(binding)))\n",
    "                bindings.append(int(input_memory))\n",
    "            else:\n",
    "                output_buffer = cuda.pagelocked_empty(size,dtype)\n",
    "                output_memory = cuda.mem_alloc(output_buffer.nbytes)\n",
    "                print(\"out\",list(engine.get_binding_shape(binding)))\n",
    "                bindings.append(int(output_memory))\n",
    "        stream = cuda.Stream()\n",
    "        \n",
    "        cuda.memcpy_htod_async(input_memory,input_buffer,stream)\n",
    "        context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
    "        cuda.memcpy_dtoh_async(output_buffer,output_memory,stream)\n",
    "        \n",
    "        stream.synchronize()\n",
    "    print(\"engine\",engine.max_batch_size)\n",
    "    print(\"output_buffer\",output_buffer.shape)\n",
    "    print(output_buffer.reshape(SHAPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b664e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading engine from file softmax_test4axis1_trt6.trt\n",
      "in [3, 4, 5]\n",
      "out [3, 4, 5]\n",
      "engine 1\n",
      "output_buffer (60,)\n",
      "[[[[0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]\n",
      "   [0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]\n",
      "   [0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]\n",
      "   [0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]]\n",
      "\n",
      "  [[0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]\n",
      "   [0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]\n",
      "   [0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]\n",
      "   [0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]]\n",
      "\n",
      "  [[0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]\n",
      "   [0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]\n",
      "   [0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]\n",
      "   [0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]]]]\n"
     ]
    }
   ],
   "source": [
    "engine_file = \"softmax_test4axis1_trt6.trt\"\n",
    "with load_engine(engine_file) as engine:\n",
    "    infer(engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
